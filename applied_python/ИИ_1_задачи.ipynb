{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. **Корутина для подсчета уникальных слов (0.5б)**  \n",
        "   Напишите корутину `unique_word_counter`, которая принимает строки (предложения), разбивает их на слова и подсчитывает уникальные слова. При отправке `None` корутина завершает выполнение и печатает итоговое количество уникальных слов.  \n",
        "   **Пример:**  \n",
        "   ```python\n",
        "   coro = unique_word_counter()\n",
        "   next(coro)\n",
        "   coro.send(\"hello world\")\n",
        "   coro.send(\"hello again\")\n",
        "   coro.send(None)  # -> должно печатать 3, так как слова \"hello\", \"world\" и \"again\" уникальны. Это должно быть только число, подумайте как возвращать значение и обрабатывать результат вызова coro.send(None)\n",
        "   ```\n",
        "\n",
        "2. **Корутина с ограничением по времени выполнения (1б)**  \n",
        "   Реализуйте корутину `timed_collector`, которая принимает целые числа и добавляет их к сумме. Если время выполнения корутины с момента ее запуска превышает заданное значение `time_limit` (в секундах), корутина завершается и возвращает текущую сумму. Считайте, что каждый yield значения из корутины занимает время, случайно распределенное между 1 и 3 секундами (реализуйте функцию для этого).\n",
        "   **Пример использования:**  \n",
        "   ```python\n",
        "   coro = timed_collector(time_limit=5)\n",
        "   next(coro)\n",
        "   coro.send(10)\n",
        "   coro.send(20)\n",
        "   coro.send(30)\n",
        "   coro.send(40)\n",
        "   coro.send(50)\n",
        "   # Через 5 секунд выполнения:\n",
        "   # Завершение, возвращает текущую сумму: 30, 60 или 100. А может, и 150?\n",
        "   # Запустите код несколько раз, убедитесь, что возвращаются разные числа!\n",
        "   # Используйте корректную обработку строк формата coro.send(...)\n",
        "   ```\n",
        "\n",
        "3. **Корутина для динамической фильтрации данных с прерыванием (1б)**  \n",
        "   Напишите корутину `dynamic_filter`, которая принимает числовые значения и фильтрует их по условию, переданному как лямбда-функция. Если отправить значение `None`, корутина завершает выполнение и возвращает список всех значений, прошедших фильтр. Если передать новое условие (новую лямбда-функцию), оно заменяет предыдущее.  \n",
        "   **Пример использования:**  \n",
        "   ```python\n",
        "   coro = dynamic_filter(lambda x: x % 2 == 0)\n",
        "   next(coro)\n",
        "   coro.send(10)  # Проходит фильтр\n",
        "   coro.send(15)  # Не проходит фильтр\n",
        "   coro.send(lambda x: x > 10)  # Изменение условия фильтрации\n",
        "   coro.send(15)  # Проходит новый фильтр\n",
        "   coro.send(None)  # Завершение, возвращает [10, 15]\n",
        "   ```\n",
        "\n",
        "4. **Циклический генератор с обработкой исключений для отдельных заданий (0.5б)**  \n",
        "   Создайте очередь заданий с помощью `deque`, где каждое задание — генератор, возвращающий числа. Реализуйте корутину `cycle_task_queue`, которая поочередно обрабатывает задания, пока очередь не опустеет. Если задание выбрасывает `StopIteration`, оно должно удаляться из очереди. Если задание выбрасывает `ValueError`, корутина должна просто пропустить это задание и перейти к следующему.  \n",
        "   **Пример использования:**  \n",
        "   ```python\n",
        "   from collections import deque\n",
        "\n",
        "   def task_1():\n",
        "       yield 1\n",
        "       yield 2\n",
        "       raise ValueError(\"Task 1 error\")\n",
        "\n",
        "   def task_2():\n",
        "       yield 3\n",
        "       yield 4\n",
        "       yield 5\n",
        "\n",
        "   tasks = deque([task_1(), task_2()])\n",
        "   coro = cycle_task_queue(tasks)\n",
        "   for item in coro:\n",
        "       print(item)\n",
        "   ```\n",
        "\n",
        "5. **Объединение данных из нескольких файлов с фильтром по содержимому, или немного искусственный пример на yield from (2б)**  \n",
        "Вам даны три генератора (`file_reader_txt`, `file_reader_csv`, `file_reader_json`), каждый из которых читает данные из файлов различных форматов: текстового (`TXT`), CSV и JSON. Эти генераторы возвращают строки из своих соответствующих файлов. Ваша задача — реализовать две корутины: `merge_filtered_files` и `filter_and_write`.\n",
        "\n",
        "- **`merge_filtered_files`** должна принимать:\n",
        "   - Функцию фильтрации `filter_func`,\n",
        "   - Имя выходного файла `output_filename`,\n",
        "   - Набор генераторов, которые предоставляют строки из разных файлов.\n",
        "\n",
        "   Корутина `merge_filtered_files` должна использовать `yield from`, чтобы объединить строки из каждого генератора в одном потоке, затем направлять их в корутину `filter_and_write` для фильтрации и записи в выходной файл.\n",
        "   \n",
        "- **`filter_and_write`** должна принимать:\n",
        "   - Функцию фильтрации `filter_func`,\n",
        "   - Объект файла для записи данных.\n",
        "   \n",
        "   `filter_and_write` будет ожидать строки от `merge_filtered_files`, фильтровать их по условию `filter_func` и записывать только те строки, которые удовлетворяют этому условию, в выходной файл.\n",
        "\n",
        "**Реализуйте решение, в котором:**\n",
        "1. `merge_filtered_files` поочередно получает строки из каждого переданного генератора, используя `yield from` (возможно, вам могут понадобиться генераторные выражения).\n",
        "2. Каждая строка направляется в `filter_and_write`, который выполняет фильтрацию и запись.\n",
        "3. В `filter_and_write` используется `yield`, чтобы реализовать взаимодействие с `yield from` в `merge_filtered_files`\n",
        "\n",
        "\n",
        "```python\n",
        "import csv\n",
        "import json\n",
        "\n",
        "# Генератор для чтения строк из текстового файла (TXT)\n",
        "def file_reader_txt(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        for line in file:\n",
        "            yield line.strip()\n",
        "\n",
        "# Генератор для чтения строк из CSV-файла\n",
        "def file_reader_csv(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        for row in reader:\n",
        "            yield ', '.join(row)  # Преобразуем каждую строку CSV в строку текста\n",
        "\n",
        "# Генератор для чтения строк из JSON-файла\n",
        "def file_reader_json(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        data = json.load(file)\n",
        "        for item in data:\n",
        "            yield json.dumps(item)  # Преобразуем каждый элемент JSON в строку\n",
        "\n",
        "# Корутина для фильтрации и записи данных в файл\n",
        "def filter_and_write(filter_func, output_file):\n",
        "    # Принимает строки от merge_filtered_files через send\n",
        "    # Применяет filter_func к каждой строке\n",
        "    # Если строка удовлетворяет условию, записывает её в output_file\n",
        "    # Использует yield для поддержания взаимодействия через yield from\n",
        "    pass\n",
        "\n",
        "# Корутина для объединения данных из нескольких генераторов с фильтрацией\n",
        "def merge_filtered_files(filter_func, output_filename, *generators):\n",
        "    # Открывает output_filename для записи\n",
        "    # Инициализирует filter_and_write для фильтрации и записи строк\n",
        "    # Использует yield from для поочередного получения строк от каждого генератора\n",
        "    # и их передачи в filter_and_write через send\n",
        "    # может быть что-то такое: yield from (writer.send(line) for line in generator), или явный цикл\n",
        "    pass\n",
        "\n",
        "# Функция фильтрации: проверяет, содержит ли строка слово \"keyword\"\n",
        "def contains_keyword(line):\n",
        "    return \"keyword\" in line\n",
        "\n",
        "# Инициализация корутины и передача генераторов для объединения\n",
        "merge = merge_filtered_files(\n",
        "    contains_keyword,\n",
        "    'merged_output.txt',\n",
        "    file_reader_txt('file1.txt'),\n",
        "    file_reader_csv('file2.csv'),\n",
        "    file_reader_json('file3.json')\n",
        ")\n",
        "\n",
        "# Запуск корутины\n",
        "for _ in merge:\n",
        "    pass\n",
        "```\n",
        "\n",
        "В результате выполнения этого кода в выходном файле `merged_output.txt` должны оказаться только те строки из всех трёх файлов (TXT, CSV, JSON), которые содержат слово `\"keyword\"`.\n",
        "\n",
        "Вот примеры файлов `file1.txt`, `file2.csv`, и `file3.json`, которые можно использовать для тестирования:\n",
        "\n",
        "### Файл 1: `file1.txt`\n",
        "\n",
        "Содержимое текстового файла:\n",
        "```\n",
        "This is a test line with keyword.\n",
        "Another line without the keyword.\n",
        "This keyword is very important.\n",
        "A simple line without the important word.\n",
        "```\n",
        "\n",
        "### Файл 2: `file2.csv`\n",
        "\n",
        "Содержимое CSV-файла:\n",
        "```\n",
        "name,description\n",
        "Alice,This description contains the keyword somewhere.\n",
        "Bob,Nothing special here.\n",
        "Carol,Another entry with keyword here.\n",
        "Dave,Just some random text without it.\n",
        "```\n",
        "\n",
        "### Файл 3: `file3.json`\n",
        "\n",
        "Содержимое JSON-файла:\n",
        "```json\n",
        "[\n",
        "    {\"id\": 1, \"text\": \"The keyword appears in this JSON object.\"},\n",
        "    {\"id\": 2, \"text\": \"This one does not have it.\"},\n",
        "    {\"id\": 3, \"text\": \"Another keyword-rich JSON line.\"},\n",
        "    {\"id\": 4, \"text\": \"Yet another line without the keyword.\"}\n",
        "]\n",
        "```\n",
        "\n",
        "### Ожидаемый результат\n",
        "\n",
        "После выполнения программы, файл `merged_output.txt` должен содержать только строки, в которых присутствует слово `\"keyword\"`:\n",
        "\n",
        "**merged_output.txt**\n",
        "```\n",
        "This is a test line with keyword.\n",
        "Another line without the keyword.\n",
        "This keyword is very important.\n",
        "Alice, This description contains the keyword somewhere.\n",
        "Carol, Another entry with keyword here.\n",
        "{\"id\": 1, \"text\": \"The keyword appears in this JSON object.\"}\n",
        "{\"id\": 3, \"text\": \"Another keyword-rich JSON line.\"}\n",
        "{\"id\": 4, \"text\": \"Yet another line without the keyword.\"}\n",
        "```\n",
        "\n",
        "### Код для создания этих файлов:\n",
        "\n",
        "```python\n",
        "with open('file1.txt', 'w') as f:\n",
        "    f.write(\"\"\"This is a test line with keyword.\n",
        "Another line without the keyword.\n",
        "This keyword is very important.\n",
        "A simple line without the important word.\"\"\")\n",
        "\n",
        "with open('file2.csv', 'w') as f:\n",
        "    f.write(\"\"\"name,description\n",
        "Alice,This description contains the keyword somewhere.\n",
        "Bob,Nothing special here.\n",
        "Carol,Another entry with keyword here.\n",
        "Dave,Just some random text without it.\"\"\")\n",
        "\n",
        "import json\n",
        "data = [\n",
        "    {\"id\": 1, \"text\": \"The keyword appears in this JSON object.\"},\n",
        "    {\"id\": 2, \"text\": \"This one does not have it.\"},\n",
        "    {\"id\": 3, \"text\": \"Another keyword-rich JSON line.\"},\n",
        "    {\"id\": 4, \"text\": \"Yet another line without the keyword.\"}\n",
        "]\n",
        "with open('file3.json', 'w') as f:\n",
        "    json.dump(data, f)\n",
        "```\n",
        "\n",
        "6. **Рекурсивное объединение и фильтрация вложенных данных (3б)**  \n",
        "\n",
        "У вас есть вложенные структуры данных, состоящие из списков и словарей, которые могут содержать строки, а могут — другие списки и словари. Ваша цель — рекурсивно пройти по всей этой структуре и получить только те строки, которые соответствуют заданной функции фильтрации `filter_func`.\n",
        "\n",
        "Реализуйте функцию `recursive_extract` — генератор, который рекурсивно обходит вложенные списки и словари, используя `yield from` для делегирования обработки вложенных структур, и возвращает строки.\n",
        "\n",
        "```python\n",
        "# Функция фильтрации\n",
        "def contains_keyword(s):\n",
        "    return \"keyword\" in s\n",
        "\n",
        "# Генератор для рекурсивного обхода и извлечения всех строк\n",
        "def recursive_extract(data):\n",
        "    # Проверяет тип data:\n",
        "    # - Если data — строка, возвращает её\n",
        "    # - Если data — словарь, рекурсивно обходит все значения словаря\n",
        "    # - Если data — список, рекурсивно обходит все элементы списка\n",
        "    # Использует yield from для делегирования обработки вложенных структур\n",
        "    pass\n",
        "\n",
        "# Функция для фильтрации строк с использованием yield from\n",
        "def filtered_strings(data, filter_func):\n",
        "    for string in recursive_extract(data):\n",
        "        if filter_func(string):\n",
        "            yield string\n",
        "\n",
        "# Вложенная структура данных\n",
        "nested_data = {\n",
        "    \"messages\": [\n",
        "        \"This is a message with keyword.\",\n",
        "        \"Just a simple message.\",\n",
        "        {\"comments\": [\"Another keyword here.\", \"Nothing here.\"]},\n",
        "        [\"List with keyword.\", \"Another list entry.\"]\n",
        "    ],\n",
        "    \"notes\": \"This is a single note without the word.\",\n",
        "    \"logs\": {\n",
        "        \"entries\": [\n",
        "            \"Log entry with keyword.\",\n",
        "            {\"subentry\": \"A nested keyword here.\"}\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Итерируемся по отфильтрованным строкам\n",
        "for line in filtered_strings(nested_data, contains_keyword):\n",
        "    print(line)\n",
        "```\n",
        "\n",
        "### Ожидаемый вывод\n",
        "\n",
        "```\n",
        "This is a message with keyword.\n",
        "Another keyword here.\n",
        "List with keyword.\n",
        "Log entry with keyword.\n",
        "A nested keyword here.\n",
        "```"
      ],
      "metadata": {
        "id": "Zh87g69y_JLW"
      }
    }
  ]
}