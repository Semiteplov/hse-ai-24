{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:48:36.224131Z",
     "start_time": "2024-12-23T05:48:36.220546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "id": "476f1de5d68fd337",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:48:37.232674Z",
     "start_time": "2024-12-23T05:48:37.229890Z"
    }
   },
   "cell_type": "code",
   "source": "RANDOM_STATE = 42",
   "id": "cc75e827cc849ff7",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-23T05:48:40.328842Z",
     "start_time": "2024-12-23T05:48:37.968911Z"
    }
   },
   "source": "df = pd.read_csv('./lenta_df.csv')",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:48:40.338370Z",
     "start_time": "2024-12-23T05:48:40.333842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "russian_stopwords = set(stopwords.words('russian'))"
   ],
   "id": "3e31b32ed1273fdc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Gulfik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Gulfik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:50:08.564879Z",
     "start_time": "2024-12-23T05:48:40.440828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Делаем токенизацию и удаляем стоп-слова с помощью библиотеки nltk\n",
    "    :param text:\n",
    "    :return токены:\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text, language='russian')\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word.lower() not in russian_stopwords]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "\n",
    "df['text'] = df['text'].dropna().apply(preprocess_text)\n",
    "cleaned_df = df.copy()\n",
    "cleaned_df.shape"
   ],
   "id": "f382f3962ec57584",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84929, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:50:08.640661Z",
     "start_time": "2024-12-23T05:50:08.613320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_df['text'], cleaned_df['bloc'], test_size=0.2,\n",
    "                                                    random_state=RANDOM_STATE)"
   ],
   "id": "70d7b11e10138c3f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Используем Tf-idf со случайными параметрами. Выбрал его вместо CountVectorizer, потому что посчитал, что tfidf учитывает редкость слов в корпусе документов.",
   "id": "9b7aeb1068082f2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:50:46.337663Z",
     "start_time": "2024-12-23T05:50:08.643653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ],
   "id": "e3cce727d3e2436e",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Обучем несколько моделей со случайными параметрами",
   "id": "dfe96b9c88762e49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:50:54.981838Z",
     "start_time": "2024-12-23T05:50:46.351694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lg = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=RANDOM_STATE)\n",
    "model_lg.fit(X_train_tfidf, y_train)\n",
    "model_lg_pred = model_lg.predict(X_test_tfidf)"
   ],
   "id": "57ef92dd6d2eb079",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:50:55.064700Z",
     "start_time": "2024-12-23T05:50:54.998349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(X_train_tfidf, y_train)\n",
    "model_nb_pred = model_nb.predict(X_test_tfidf)"
   ],
   "id": "bcfa834bbfd4993e",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:53:55.376193Z",
     "start_time": "2024-12-23T05:50:55.078749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=200, max_depth=30)\n",
    "model_rf.fit(X_train_tfidf, y_train)\n",
    "model_rf_pred = model_rf.predict(X_test_tfidf)"
   ],
   "id": "2b9d6c6c8c09e56d",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:54:05.637558Z",
     "start_time": "2024-12-23T05:53:55.413463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model_svm = LinearSVC(random_state=RANDOM_STATE, C=1)\n",
    "model_svm.fit(X_train_tfidf, y_train)\n",
    "model_svm_pred = model_svm.predict(X_test_tfidf)"
   ],
   "id": "722250ada9971fbf",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:54:42.308427Z",
     "start_time": "2024-12-23T05:54:05.642557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_tree = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=30)\n",
    "model_tree.fit(X_train_tfidf, y_train)\n",
    "model_tree_pred = model_tree.predict(X_test_tfidf)"
   ],
   "id": "6ef0cfc29a44fdd3",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:54:42.491623Z",
     "start_time": "2024-12-23T05:54:42.361291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(f'Logistic regression report: {classification_report(y_test, model_lg_pred)}')\n",
    "print(f'NB report: {classification_report(y_test, model_nb_pred)}')\n",
    "print(f'Random forest report: {classification_report(y_test, model_rf_pred)}')\n",
    "print(f'SVM report: {classification_report(y_test, model_svm_pred)}')\n",
    "print(f'Decision tree report: {classification_report(y_test, model_tree_pred)}')\n",
    "# print(f'XGB classifier report: {classification_report(y_test, model_xgb_pred)}')"
   ],
   "id": "adcaa7c5cc4777e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      1978\n",
      "           1       0.87      0.91      0.89      2015\n",
      "           2       0.95      0.96      0.95      2024\n",
      "           3       0.92      0.95      0.93      1934\n",
      "           4       0.99      0.99      0.99      1936\n",
      "           5       0.99      0.99      0.99      1851\n",
      "           6       0.83      0.70      0.76      1170\n",
      "           7       0.98      0.98      0.98      2063\n",
      "           8       0.96      0.96      0.96      2015\n",
      "\n",
      "    accuracy                           0.94     16986\n",
      "   macro avg       0.93      0.92      0.93     16986\n",
      "weighted avg       0.93      0.94      0.93     16986\n",
      "\n",
      "NB report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76      1978\n",
      "           1       0.77      0.84      0.80      2015\n",
      "           2       0.86      0.95      0.90      2024\n",
      "           3       0.83      0.93      0.87      1934\n",
      "           4       0.99      0.94      0.97      1936\n",
      "           5       0.91      0.99      0.95      1851\n",
      "           6       0.62      0.43      0.50      1170\n",
      "           7       0.95      0.94      0.94      2063\n",
      "           8       0.95      0.93      0.94      2015\n",
      "\n",
      "    accuracy                           0.87     16986\n",
      "   macro avg       0.85      0.85      0.85     16986\n",
      "weighted avg       0.87      0.87      0.86     16986\n",
      "\n",
      "Random forest report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76      1978\n",
      "           1       0.72      0.89      0.79      2015\n",
      "           2       0.88      0.94      0.91      2024\n",
      "           3       0.81      0.92      0.86      1934\n",
      "           4       0.98      0.99      0.99      1936\n",
      "           5       0.96      0.99      0.97      1851\n",
      "           6       0.80      0.52      0.63      1170\n",
      "           7       0.96      0.96      0.96      2063\n",
      "           8       0.96      0.87      0.91      2015\n",
      "\n",
      "    accuracy                           0.88     16986\n",
      "   macro avg       0.88      0.86      0.86     16986\n",
      "weighted avg       0.88      0.88      0.88     16986\n",
      "\n",
      "SVM report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      1978\n",
      "           1       0.88      0.89      0.89      2015\n",
      "           2       0.95      0.95      0.95      2024\n",
      "           3       0.92      0.94      0.93      1934\n",
      "           4       0.99      1.00      0.99      1936\n",
      "           5       0.99      0.99      0.99      1851\n",
      "           6       0.81      0.73      0.77      1170\n",
      "           7       0.98      0.98      0.98      2063\n",
      "           8       0.96      0.97      0.96      2015\n",
      "\n",
      "    accuracy                           0.93     16986\n",
      "   macro avg       0.93      0.93      0.93     16986\n",
      "weighted avg       0.93      0.93      0.93     16986\n",
      "\n",
      "Decision tree report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.81      0.49      1978\n",
      "           1       0.70      0.34      0.46      2015\n",
      "           2       0.87      0.68      0.76      2024\n",
      "           3       0.76      0.72      0.74      1934\n",
      "           4       1.00      0.90      0.95      1936\n",
      "           5       0.98      0.95      0.96      1851\n",
      "           6       0.80      0.65      0.72      1170\n",
      "           7       0.97      0.90      0.93      2063\n",
      "           8       0.96      0.82      0.89      2015\n",
      "\n",
      "    accuracy                           0.75     16986\n",
      "   macro avg       0.82      0.75      0.77     16986\n",
      "weighted avg       0.82      0.75      0.77     16986\n",
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Посмотрим на roc_auc Logistic Regression",
   "id": "84893b1d94079f9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:56:41.354990Z",
     "start_time": "2024-12-23T05:56:41.297351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model_lg_proba = model_lg.predict_proba(X_test_tfidf)\n",
    "roc_auc = roc_auc_score(y_test, model_lg_proba, multi_class='ovr')\n",
    "\n",
    "print('ROC AUC для log reg:', roc_auc)"
   ],
   "id": "fe3dac9e75d0ff70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC для log reg: 0.9956553398582252\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Из репортов видно, что лучше всего с задачей справились линейная SVM и Logistic Regression. Скорее всего они справились лучше всего, так как я использовал tf-idf, и после этой обработки признаков, данные стали линейно разделимы.\n",
    "\n",
    "Попрубем подобрать параметры для Logistic Regression, и, например, для Random Forest:"
   ],
   "id": "a2eebf4db190ccb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T20:59:48.646125Z",
     "start_time": "2024-12-22T17:52:46.413895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    # Параметры TF-IDF\n",
    "    'tfidf__max_features': [5000, 10000, 20000],     # Максимальное количество признаков (токенов)\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],  # Диапазон n-грамм (униграммы, биграммы, триграммы)\n",
    "    'tfidf__min_df': [1, 2, 5],                      # Минимальная частота документа для включения токена\n",
    "    'tfidf__max_df': [0.8, 0.9, 1.0],                # Максимальная доля документов, содержащих токен\n",
    "\n",
    "    # Параметры Logistic Regression\n",
    "    'logreg__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'logreg__solver': ['lbfgs', 'liblinear'],\n",
    "    'logreg__penalty': ['l2'],\n",
    "    'logreg__max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Лучшие параметры Logistic Regression:', grid_search.best_params_)\n",
    "print('Лучшая точность на валидации:', grid_search.best_score_)\n",
    "\n",
    "best_lg_pipeline = grid_search.best_estimator_\n",
    "lg_pred = best_lg_pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, lg_pred))"
   ],
   "id": "ec3ec98cbb745ad0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2430 candidates, totalling 7290 fits\n",
      "Лучшие параметры Logistic Regression: {'logreg__C': 100, 'logreg__max_iter': 100, 'logreg__penalty': 'l2', 'logreg__solver': 'liblinear', 'tfidf__max_df': 1.0, 'tfidf__max_features': 20000, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n",
      "Лучшая точность на валидации: 0.9213333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       469\n",
      "           1       0.86      0.88      0.87       498\n",
      "           2       0.94      0.95      0.95       472\n",
      "           3       0.92      0.93      0.93       543\n",
      "           4       0.99      1.00      0.99       474\n",
      "           5       0.99      0.99      0.99       561\n",
      "           6       0.85      0.77      0.81       489\n",
      "           7       0.98      0.98      0.98       477\n",
      "           8       0.95      0.95      0.95       517\n",
      "\n",
      "    accuracy                           0.92      4500\n",
      "   macro avg       0.92      0.92      0.92      4500\n",
      "weighted avg       0.92      0.92      0.92      4500\n",
      "\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T04:58:21.756666Z",
     "start_time": "2024-12-23T04:46:13.987918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# Параметры\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [20000],\n",
    "    'tfidf__ngram_range': [(1, 2)],\n",
    "    'tfidf__min_df': [5],\n",
    "\n",
    "    'rf__n_estimators': [100, 200, 500],\n",
    "    'rf__max_depth': [10, 20, 30],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Лучшие параметры RandomForest:', grid_search.best_params_)\n",
    "print('Лучшая точность на валидации:', grid_search.best_score_)\n",
    "\n",
    "best_rf_pipeline = grid_search.best_estimator_\n",
    "rf_pred = best_rf_pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, rf_pred))"
   ],
   "id": "dbf178d8221aad03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gulfik\\Desktop\\petprojects\\hseContest\\.venv\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры RandomForest: {'rf__max_depth': 30, 'rf__min_samples_leaf': 4, 'rf__min_samples_split': 10, 'rf__n_estimators': 500, 'tfidf__max_features': 20000, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n",
      "Лучшая точность на валидации: 0.8819444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75       469\n",
      "           1       0.80      0.84      0.82       498\n",
      "           2       0.86      0.94      0.90       472\n",
      "           3       0.84      0.92      0.88       543\n",
      "           4       0.96      0.99      0.98       474\n",
      "           5       0.95      0.99      0.97       561\n",
      "           6       0.90      0.73      0.81       489\n",
      "           7       0.96      0.96      0.96       477\n",
      "           8       0.94      0.87      0.90       517\n",
      "\n",
      "    accuracy                           0.89      4500\n",
      "   macro avg       0.89      0.89      0.89      4500\n",
      "weighted avg       0.89      0.89      0.89      4500\n",
      "\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Как видно из репорта, модели хуже всего определяют нулевой класс (тему 'Общество/Россия'). Также модели не улучшились после подбора параметров. Вероятно, это связано с тем, что данные после tf-idf уже хорошо разделимы, поэтому для улучшения можно заняться созданием новых признаков или улучшить препобработку данных.",
   "id": "a9ca7d0df9f6cea6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Обучим на тестовых данных и сохраним submission:",
   "id": "b505df60b0d7c634"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:55:20.363597Z",
     "start_time": "2024-12-23T05:54:42.495626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_df = pd.read_csv('./test_news.csv')\n",
    "test_df['cleaned_text'] = test_df['content'].apply(preprocess_text)\n",
    "y_pred_test = model_lg.predict(test_df['cleaned_text'])\n",
    "pd.DataFrame({'topic': y_pred_test}).reset_index().to_csv('submission.csv', index=False)"
   ],
   "id": "213416893a06bfbb",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Фото обороны ДНР Игорю Стрелкову Гиркину пришлось уйти подполье встретиться Петербурге тридцатью поклонниками создании нужной атмосферы задействованы автозак Росгвардии кинолог одна собака четыре полицейские машины чертова дюжина силовиков последние семь лет Стрелков Гиркин выступал Петербурге столь часто это само перестало событием Предыдущий собирал аншлаг той Листве январе Книжная лавка Листва Литейном проспекте принадлежит издательству Черная сотня самом названии которого содержится указание правый характер сподвижников считают обществом патриотов регулярной основе проходят встречи читателями Военкор Владлен Татарский приходил сюда несколько часов взорванной Университетской набережной бомбы Бывала Листве Дарья Дугина Весной выступал самый известный путчем маршем Пригожина мятежник полковник Квачков Фото Листва ПетербургФото Листва ПетербургПоделитьсяКак правило рядовые встречи Листве проводятся счет довольно символических пожертвований пользу русской армии лекцию Стрелковым темой заявлен мятеж ЧВК Вагнер количество билетов ограничили двадцатью цену увеличили 8 4 000 рублей Часть денег подчеркивают организаторы предполагалось потратить охрану остальные нужды фронта учетом ограниченного количества мест речь идет сумме меньше 100 тысяч рублей встречи Листва заявила фронт отправят вырученные средства совпало сразу анонса Стрелкова полиция начала проявлять интерес людям Листвы Точнее одному человеку организатору мероприятий магазина члену правого движения Савве Федосееву Первый задержали уличного конфликта который назвал бытовым Федосеева отпустили протокола время второго задержания буквально дня лекции информационное поле вброшены националистические мотивы полиция сообщила предотвратила массовую драку Фото Алина Ампелонская Фото Алина Ампелонская Фото Алина Ампелонская ПоделитьсяТем временем разминирование Листвы походило обыск Ассортимент книжного магазина полицейские изучали кинолога вместе собакой уехал свое Янино словам сотрудников лавки силовики отрубили камеры внутрь пускали числе адвоката Официальных комментариев объяснений стороны полиции последовало следующий день 10 Листва ПетербургФото Листва ПетербургФото Листва ПетербургФото Листва ПетербургФото Листва ПетербургПоделиться новой локации участников проинформировали телефону Свое помещение предоставило петербургское отделение партии Другая Россия Лимонова Федосеев рассказал Фонтанке заранее подготовили запасной план слушатель утверждают Листве отказался приехали Аудитория итоге увеличилась 30 человек входе охрана досмотрела рюкзаки сумки присутствующих попросили воздержаться публикации фотографий конца мероприятия добавили адвокат прибудет полиция присутствует Фото Фото Фото Поделиться лекцию Стрелков прибыл ровно восьми часам Пошутил жена просила уложиться 15 минут Лекция обошлась откровений обороны сразу сказал практически обо всем писал своем информация инсайдерская основанная собственном анализе Минут сорок говорил непосредственно мятеже лишним часа отвечал вопросы немного следите обычно говорит пишет Стрелков основные тезисы вероятно угадаете протяжении вечера атмосфера напряженной Звук проезжающих мимо машин заставлял прислушиваться едут гости Стрелков иронизировал даст бог доживет 53 Разошлись одиннадцати сделав прощание памятную фотокарточку имперским флагом Фото Фото Федор Данилов'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m test_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./test_news.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m test_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcleaned_text\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m test_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(preprocess_text)\n\u001B[1;32m----> 3\u001B[0m y_pred_test \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_lg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcleaned_text\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtopic\u001B[39m\u001B[38;5;124m'\u001B[39m: y_pred_test})\u001B[38;5;241m.\u001B[39mreset_index()\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msubmission.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Desktop\\petprojects\\hseContest\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:382\u001B[0m, in \u001B[0;36mLinearClassifierMixin.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    368\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    369\u001B[0m \u001B[38;5;124;03mPredict class labels for samples in X.\u001B[39;00m\n\u001B[0;32m    370\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;124;03m    Vector containing the class labels for each sample.\u001B[39;00m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    381\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[1;32m--> 382\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecision_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(scores\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    384\u001B[0m     indices \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(scores \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, indexing_dtype(xp))\n",
      "File \u001B[1;32m~\\Desktop\\petprojects\\hseContest\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:363\u001B[0m, in \u001B[0;36mLinearClassifierMixin.decision_function\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    360\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    361\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[1;32m--> 363\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    364\u001B[0m scores \u001B[38;5;241m=\u001B[39m safe_sparse_dot(X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoef_\u001B[38;5;241m.\u001B[39mT, dense_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_\n\u001B[0;32m    365\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39mreshape(scores, (\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,)) \u001B[38;5;28;01mif\u001B[39;00m scores\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m scores\n",
      "File \u001B[1;32m~\\Desktop\\petprojects\\hseContest\\.venv\\Lib\\site-packages\\sklearn\\base.py:633\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    631\u001B[0m         out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[1;32m--> 633\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[0;32m    635\u001B[0m     out \u001B[38;5;241m=\u001B[39m _check_y(y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n",
      "File \u001B[1;32m~\\Desktop\\petprojects\\hseContest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m   1010\u001B[0m         array \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(array, dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1011\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1012\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43m_asarray_with_order\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1013\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[0;32m   1014\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1015\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[0;32m   1016\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\petprojects\\hseContest\\.venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:745\u001B[0m, in \u001B[0;36m_asarray_with_order\u001B[1;34m(array, dtype, order, copy, xp, device)\u001B[0m\n\u001B[0;32m    743\u001B[0m     array \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39marray(array, order\u001B[38;5;241m=\u001B[39morder, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 745\u001B[0m     array \u001B[38;5;241m=\u001B[39m \u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001B[39;00m\n\u001B[0;32m    748\u001B[0m \u001B[38;5;66;03m# container that is consistent with the input's namespace.\u001B[39;00m\n\u001B[0;32m    749\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39masarray(array)\n",
      "File \u001B[1;32m~\\Desktop\\petprojects\\hseContest\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1031\u001B[0m, in \u001B[0;36mSeries.__array__\u001B[1;34m(self, dtype, copy)\u001B[0m\n\u001B[0;32m    981\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    982\u001B[0m \u001B[38;5;124;03mReturn the values as a NumPy array.\u001B[39;00m\n\u001B[0;32m    983\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1028\u001B[0m \u001B[38;5;124;03m      dtype='datetime64[ns]')\u001B[39;00m\n\u001B[0;32m   1029\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1030\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m-> 1031\u001B[0m arr \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1032\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m using_copy_on_write() \u001B[38;5;129;01mand\u001B[39;00m astype_is_view(values\u001B[38;5;241m.\u001B[39mdtype, arr\u001B[38;5;241m.\u001B[39mdtype):\n\u001B[0;32m   1033\u001B[0m     arr \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mview()\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'Фото обороны ДНР Игорю Стрелкову Гиркину пришлось уйти подполье встретиться Петербурге тридцатью поклонниками создании нужной атмосферы задействованы автозак Росгвардии кинолог одна собака четыре полицейские машины чертова дюжина силовиков последние семь лет Стрелков Гиркин выступал Петербурге столь часто это само перестало событием Предыдущий собирал аншлаг той Листве январе Книжная лавка Листва Литейном проспекте принадлежит издательству Черная сотня самом названии которого содержится указание правый характер сподвижников считают обществом патриотов регулярной основе проходят встречи читателями Военкор Владлен Татарский приходил сюда несколько часов взорванной Университетской набережной бомбы Бывала Листве Дарья Дугина Весной выступал самый известный путчем маршем Пригожина мятежник полковник Квачков Фото Листва ПетербургФото Листва ПетербургПоделитьсяКак правило рядовые встречи Листве проводятся счет довольно символических пожертвований пользу русской армии лекцию Стрелковым темой заявлен мятеж ЧВК Вагнер количество билетов ограничили двадцатью цену увеличили 8 4 000 рублей Часть денег подчеркивают организаторы предполагалось потратить охрану остальные нужды фронта учетом ограниченного количества мест речь идет сумме меньше 100 тысяч рублей встречи Листва заявила фронт отправят вырученные средства совпало сразу анонса Стрелкова полиция начала проявлять интерес людям Листвы Точнее одному человеку организатору мероприятий магазина члену правого движения Савве Федосееву Первый задержали уличного конфликта который назвал бытовым Федосеева отпустили протокола время второго задержания буквально дня лекции информационное поле вброшены националистические мотивы полиция сообщила предотвратила массовую драку Фото Алина Ампелонская Фото Алина Ампелонская Фото Алина Ампелонская ПоделитьсяТем временем разминирование Листвы походило обыск Ассортимент книжного магазина полицейские изучали кинолога вместе собакой уехал свое Янино словам сотрудников лавки силовики отрубили камеры внутрь пускали числе адвоката Официальных комментариев объяснений стороны полиции последовало следующий день 10 Листва ПетербургФото Листва ПетербургФото Листва ПетербургФото Листва ПетербургФото Листва ПетербургПоделиться новой локации участников проинформировали телефону Свое помещение предоставило петербургское отделение партии Другая Россия Лимонова Федосеев рассказал Фонтанке заранее подготовили запасной план слушатель утверждают Листве отказался приехали Аудитория итоге увеличилась 30 человек входе охрана досмотрела рюкзаки сумки присутствующих попросили воздержаться публикации фотографий конца мероприятия добавили адвокат прибудет полиция присутствует Фото Фото Фото Поделиться лекцию Стрелков прибыл ровно восьми часам Пошутил жена просила уложиться 15 минут Лекция обошлась откровений обороны сразу сказал практически обо всем писал своем информация инсайдерская основанная собственном анализе Минут сорок говорил непосредственно мятеже лишним часа отвечал вопросы немного следите обычно говорит пишет Стрелков основные тезисы вероятно угадаете протяжении вечера атмосфера напряженной Звук проезжающих мимо машин заставлял прислушиваться едут гости Стрелков иронизировал даст бог доживет 53 Разошлись одиннадцати сделав прощание памятную фотокарточку имперским флагом Фото Фото Федор Данилов'"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:57:36.524122Z",
     "start_time": "2024-12-23T05:56:49.616023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_df = pd.read_csv('./test_news.csv')\n",
    "test_df['cleaned_text'] = test_df['content'].apply(preprocess_text)\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(test_df['cleaned_text'])\n",
    "y_pred_test = model_lg.predict(X_test_tfidf)\n",
    "\n",
    "pd.DataFrame({'topic': y_pred_test}).reset_index().to_csv('submission.csv', index=False)"
   ],
   "id": "41a9a1163acf1368",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T19:28:55.743469Z",
     "start_time": "2024-12-23T10:08:42.872039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Пайплайн с TfidfVectorizer и SVM\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svm', SVC(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# Параметры для настройки\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [20000],\n",
    "    'tfidf__ngram_range': [(1, 2)],\n",
    "    'tfidf__min_df': [5],\n",
    "\n",
    "    'svm__kernel': ['poly', 'sigmoid'],  # Типы ядер\n",
    "    'svm__C': [10, 100],                         # Регуляризация\n",
    "    'svm__gamma': [0.1, 1],             # Масштабирование (для rbf, poly, sigmoid)\n",
    "    'svm__degree': [2, 3, 4]                             # Только для poly\n",
    "}\n",
    "\n",
    "# Настройка GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Результаты\n",
    "print('Лучшие параметры SVM:', grid_search.best_params_)\n",
    "print('Лучшая точность на валидации:', grid_search.best_score_)\n",
    "\n",
    "# Оценка модели на тестовых данных\n",
    "best_svm_pipeline = grid_search.best_estimator_\n",
    "svm_pred = best_svm_pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, svm_pred))\n"
   ],
   "id": "bba971fbd3ce8970",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Лучшие параметры SVM: {'svm__C': 10, 'svm__degree': 2, 'svm__gamma': 0.1, 'svm__kernel': 'sigmoid', 'tfidf__max_features': 20000, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n",
      "Лучшая точность на валидации: 0.9355489190080047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      1978\n",
      "           1       0.91      0.91      0.91      2015\n",
      "           2       0.95      0.95      0.95      2024\n",
      "           3       0.93      0.94      0.94      1934\n",
      "           4       1.00      0.99      1.00      1936\n",
      "           5       0.99      0.99      0.99      1851\n",
      "           6       0.83      0.78      0.80      1170\n",
      "           7       0.99      0.98      0.98      2063\n",
      "           8       0.96      0.97      0.96      2015\n",
      "\n",
      "    accuracy                           0.94     16986\n",
      "   macro avg       0.94      0.93      0.94     16986\n",
      "weighted avg       0.94      0.94      0.94     16986\n",
      "\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T19:38:11.287482Z",
     "start_time": "2024-12-23T19:28:55.799327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_df = pd.read_csv('./test_news.csv')\n",
    "test_df['cleaned_text'] = test_df['content'].apply(preprocess_text)\n",
    "y_pred_test = best_svm_pipeline.predict(test_df['cleaned_text'])\n",
    "pd.DataFrame({'topic': y_pred_test}).reset_index().to_csv('submission.csv', index=False)"
   ],
   "id": "68e82e298f07fee5",
   "outputs": [],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
