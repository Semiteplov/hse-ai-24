{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T15:07:50.516192Z",
     "start_time": "2024-12-22T15:07:50.513207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "id": "476f1de5d68fd337",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T15:07:51.051305Z",
     "start_time": "2024-12-22T15:07:51.047914Z"
    }
   },
   "cell_type": "code",
   "source": "RANDOM_STATE = 42",
   "id": "cc75e827cc849ff7",
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-22T15:07:52.242811Z",
     "start_time": "2024-12-22T15:07:51.592662Z"
    }
   },
   "source": "df = pd.read_csv('./lenta_df.csv')",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T15:07:52.583806Z",
     "start_time": "2024-12-22T15:07:52.247323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "russian_stopwords = set(stopwords.words('russian'))"
   ],
   "id": "3e31b32ed1273fdc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Gulfik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Gulfik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T15:08:17.386849Z",
     "start_time": "2024-12-22T15:07:53.807105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Делаем токенизацию и удаляем стоп-слова с помощью библиотеки nltk\n",
    "    :param text:\n",
    "    :return токены:\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text, language='russian')\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word.lower() not in russian_stopwords]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "\n",
    "df['text'] = df['text'].dropna().apply(preprocess_text)\n",
    "cleaned_df = df.copy()\n",
    "cleaned_df.shape"
   ],
   "id": "f382f3962ec57584",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T15:08:17.401451Z",
     "start_time": "2024-12-22T15:08:17.394574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_df['text'], cleaned_df['bloc'], test_size=0.2,\n",
    "                                                    random_state=RANDOM_STATE)"
   ],
   "id": "70d7b11e10138c3f",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Используем Tf-idf со случайными параметрами. Выбрал его вместо CountVectorizer, потому что посчитал, что tfidf учитывает редкость слов в корпусе документов.",
   "id": "9b7aeb1068082f2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T15:08:28.546375Z",
     "start_time": "2024-12-22T15:08:17.466032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ],
   "id": "e3cce727d3e2436e",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Обучем несколько моделей со случайными параметрами",
   "id": "dfe96b9c88762e49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T15:08:30.981744Z",
     "start_time": "2024-12-22T15:08:28.549375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lg = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=RANDOM_STATE)\n",
    "model_lg.fit(X_train_tfidf, y_train)\n",
    "model_lg_pred = model_lg.predict(X_test_tfidf)"
   ],
   "id": "57ef92dd6d2eb079",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T15:08:31.035021Z",
     "start_time": "2024-12-22T15:08:31.013016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(X_train_tfidf, y_train)\n",
    "model_nb_pred = model_nb.predict(X_test_tfidf)"
   ],
   "id": "bcfa834bbfd4993e",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T15:18:21.117832Z",
     "start_time": "2024-12-22T15:16:35.540118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=200, max_depth=30)\n",
    "model_rf.fit(X_train_tfidf, y_train)\n",
    "model_rf_pred = model_rf.predict(X_test_tfidf)"
   ],
   "id": "2b9d6c6c8c09e56d",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T15:08:35.300352Z",
     "start_time": "2024-12-22T15:08:32.716602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model_svm = LinearSVC(random_state=RANDOM_STATE, C=1)\n",
    "model_svm.fit(X_train_tfidf, y_train)\n",
    "model_svm_pred = model_svm.predict(X_test_tfidf)"
   ],
   "id": "722250ada9971fbf",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T15:09:31.367710Z",
     "start_time": "2024-12-22T15:09:23.866897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_tree = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=30)\n",
    "model_tree.fit(X_train_tfidf, y_train)\n",
    "model_tree_pred = model_tree.predict(X_test_tfidf)"
   ],
   "id": "6ef0cfc29a44fdd3",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T15:18:24.076385Z",
     "start_time": "2024-12-22T15:18:24.031049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(f'Logistic regression report: {classification_report(y_test, model_lg_pred)}')\n",
    "print(f'NB report: {classification_report(y_test, model_nb_pred)}')\n",
    "print(f'Random forest report: {classification_report(y_test, model_rf_pred)}')\n",
    "print(f'SVM report: {classification_report(y_test, model_svm_pred)}')\n",
    "print(f'Decision tree report: {classification_report(y_test, model_tree_pred)}')\n",
    "# print(f'XGB classifier report: {classification_report(y_test, model_xgb_pred)}')"
   ],
   "id": "adcaa7c5cc4777e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       469\n",
      "           1       0.88      0.87      0.88       498\n",
      "           2       0.94      0.96      0.95       472\n",
      "           3       0.91      0.93      0.92       543\n",
      "           4       0.99      1.00      1.00       474\n",
      "           5       0.99      0.99      0.99       561\n",
      "           6       0.84      0.77      0.81       489\n",
      "           7       0.99      0.97      0.98       477\n",
      "           8       0.95      0.94      0.94       517\n",
      "\n",
      "    accuracy                           0.92      4500\n",
      "   macro avg       0.92      0.92      0.92      4500\n",
      "weighted avg       0.92      0.92      0.92      4500\n",
      "\n",
      "NB report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.69      0.73       469\n",
      "           1       0.78      0.82      0.80       498\n",
      "           2       0.83      0.96      0.89       472\n",
      "           3       0.81      0.93      0.87       543\n",
      "           4       0.98      0.96      0.97       474\n",
      "           5       0.94      0.99      0.96       561\n",
      "           6       0.72      0.48      0.57       489\n",
      "           7       0.95      0.95      0.95       477\n",
      "           8       0.93      0.94      0.93       517\n",
      "\n",
      "    accuracy                           0.86      4500\n",
      "   macro avg       0.86      0.86      0.85      4500\n",
      "weighted avg       0.86      0.86      0.86      4500\n",
      "\n",
      "Random forest report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77       469\n",
      "           1       0.76      0.86      0.81       498\n",
      "           2       0.89      0.93      0.91       472\n",
      "           3       0.85      0.90      0.88       543\n",
      "           4       0.96      0.98      0.97       474\n",
      "           5       0.95      0.99      0.97       561\n",
      "           6       0.87      0.73      0.79       489\n",
      "           7       0.97      0.95      0.96       477\n",
      "           8       0.93      0.86      0.90       517\n",
      "\n",
      "    accuracy                           0.89      4500\n",
      "   macro avg       0.89      0.88      0.88      4500\n",
      "weighted avg       0.89      0.89      0.89      4500\n",
      "\n",
      "SVM report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.84       469\n",
      "           1       0.86      0.87      0.87       498\n",
      "           2       0.95      0.95      0.95       472\n",
      "           3       0.93      0.93      0.93       543\n",
      "           4       0.99      1.00      1.00       474\n",
      "           5       0.99      1.00      0.99       561\n",
      "           6       0.85      0.79      0.82       489\n",
      "           7       0.98      0.98      0.98       477\n",
      "           8       0.95      0.94      0.94       517\n",
      "\n",
      "    accuracy                           0.93      4500\n",
      "   macro avg       0.92      0.93      0.92      4500\n",
      "weighted avg       0.93      0.93      0.93      4500\n",
      "\n",
      "Decision tree report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.84      0.49       469\n",
      "           1       0.65      0.31      0.42       498\n",
      "           2       0.90      0.73      0.80       472\n",
      "           3       0.85      0.63      0.73       543\n",
      "           4       0.96      0.94      0.95       474\n",
      "           5       0.96      0.94      0.95       561\n",
      "           6       0.87      0.79      0.83       489\n",
      "           7       0.98      0.91      0.94       477\n",
      "           8       0.94      0.82      0.87       517\n",
      "\n",
      "    accuracy                           0.77      4500\n",
      "   macro avg       0.83      0.77      0.78      4500\n",
      "weighted avg       0.83      0.77      0.78      4500\n",
      "\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Посмотрим на roc_auc Logistic Regression",
   "id": "84893b1d94079f9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T16:39:26.486726Z",
     "start_time": "2024-12-22T16:39:26.467969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model_lg_proba = model_lg.predict_proba(X_test_tfidf)\n",
    "roc_auc = roc_auc_score(y_test, model_lg_proba, multi_class='ovr')\n",
    "\n",
    "print('ROC AUC для log reg:', roc_auc)"
   ],
   "id": "fe3dac9e75d0ff70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC для log reg: 0.9939003199774606\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Из репортов видно, что лучше всего с задачей справились линейная SVM и Logistic Regression. Скорее всего они справились лучше всего, так как я использовал tf-idf, и после этой обработки признаков, данные стали линейно разделимы.\n",
    "\n",
    "Попрубем подобрать параметры для Logistic Regression, и, например, для Random Forest:"
   ],
   "id": "a2eebf4db190ccb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T20:59:48.646125Z",
     "start_time": "2024-12-22T17:52:46.413895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    # Параметры TF-IDF\n",
    "    'tfidf__max_features': [5000, 10000, 20000],     # Максимальное количество признаков (токенов)\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],  # Диапазон n-грамм (униграммы, биграммы, триграммы)\n",
    "    'tfidf__min_df': [1, 2, 5],                      # Минимальная частота документа для включения токена\n",
    "    'tfidf__max_df': [0.8, 0.9, 1.0],                # Максимальная доля документов, содержащих токен\n",
    "\n",
    "    # Параметры Logistic Regression\n",
    "    'logreg__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'logreg__solver': ['lbfgs', 'liblinear'],\n",
    "    'logreg__penalty': ['l2'],\n",
    "    'logreg__max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Лучшие параметры Logistic Regression:', grid_search.best_params_)\n",
    "print('Лучшая точность на валидации:', grid_search.best_score_)\n",
    "\n",
    "best_lg_pipeline = grid_search.best_estimator_\n",
    "lg_pred = best_lg_pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, lg_pred))"
   ],
   "id": "ec3ec98cbb745ad0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2430 candidates, totalling 7290 fits\n",
      "Лучшие параметры Logistic Regression: {'logreg__C': 100, 'logreg__max_iter': 100, 'logreg__penalty': 'l2', 'logreg__solver': 'liblinear', 'tfidf__max_df': 1.0, 'tfidf__max_features': 20000, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n",
      "Лучшая точность на валидации: 0.9213333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       469\n",
      "           1       0.86      0.88      0.87       498\n",
      "           2       0.94      0.95      0.95       472\n",
      "           3       0.92      0.93      0.93       543\n",
      "           4       0.99      1.00      0.99       474\n",
      "           5       0.99      0.99      0.99       561\n",
      "           6       0.85      0.77      0.81       489\n",
      "           7       0.98      0.98      0.98       477\n",
      "           8       0.95      0.95      0.95       517\n",
      "\n",
      "    accuracy                           0.92      4500\n",
      "   macro avg       0.92      0.92      0.92      4500\n",
      "weighted avg       0.92      0.92      0.92      4500\n",
      "\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T04:58:21.756666Z",
     "start_time": "2024-12-23T04:46:13.987918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# Параметры\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [20000],\n",
    "    'tfidf__ngram_range': [(1, 2)],\n",
    "    'tfidf__min_df': [5],\n",
    "\n",
    "    'rf__n_estimators': [100, 200, 500],\n",
    "    'rf__max_depth': [10, 20, 30],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Лучшие параметры RandomForest:', grid_search.best_params_)\n",
    "print('Лучшая точность на валидации:', grid_search.best_score_)\n",
    "\n",
    "best_rf_pipeline = grid_search.best_estimator_\n",
    "rf_pred = best_rf_pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, rf_pred))"
   ],
   "id": "dbf178d8221aad03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gulfik\\Desktop\\petprojects\\hseContest\\.venv\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры RandomForest: {'rf__max_depth': 30, 'rf__min_samples_leaf': 4, 'rf__min_samples_split': 10, 'rf__n_estimators': 500, 'tfidf__max_features': 20000, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n",
      "Лучшая точность на валидации: 0.8819444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75       469\n",
      "           1       0.80      0.84      0.82       498\n",
      "           2       0.86      0.94      0.90       472\n",
      "           3       0.84      0.92      0.88       543\n",
      "           4       0.96      0.99      0.98       474\n",
      "           5       0.95      0.99      0.97       561\n",
      "           6       0.90      0.73      0.81       489\n",
      "           7       0.96      0.96      0.96       477\n",
      "           8       0.94      0.87      0.90       517\n",
      "\n",
      "    accuracy                           0.89      4500\n",
      "   macro avg       0.89      0.89      0.89      4500\n",
      "weighted avg       0.89      0.89      0.89      4500\n",
      "\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Как видно из репорта, модели хуже всего определяют нулевой класс (тему 'Общество/Россия'). Также модели не улучшились после подбора параметров. Вероятно, это связано с тем, что данные после tf-idf уже хорошо разделимы, поэтому для улучшения можно заняться созданием новых признаков или улучшить препобработку данных.",
   "id": "a9ca7d0df9f6cea6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Обучим на тестовых данных и сохраним submission:",
   "id": "b505df60b0d7c634"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T05:02:45.365985Z",
     "start_time": "2024-12-23T05:01:58.687025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_df = pd.read_csv('./test_news.csv')\n",
    "test_df['cleaned_text'] = test_df['content'].apply(preprocess_text)\n",
    "y_pred_test = best_lg_pipeline.predict(test_df['cleaned_text'])\n",
    "pd.DataFrame({'topic': y_pred_test}).reset_index().to_csv('submission.csv', index=False)"
   ],
   "id": "213416893a06bfbb",
   "outputs": [],
   "execution_count": 118
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
